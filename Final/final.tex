\documentclass[usletter]{article}
\usepackage[margin=1.5in]{geometry}

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{cancel}
\usepackage[mathscr]{eucal}

\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{enumitem}
\usepackage{graphicx}

\usepackage{scribe}

\newcommand {\namedset}[1]     {\ensuremath{\mathbb{#1}}}
\newcommand {\langset}[1]      {\ensuremath{\mathcal{#1}}}
\newcommand {\machine}[1]      {\ensuremath{\mathscr{#1}}}
\newcommand {\langfunc}        {\ensuremath{\mathfrak{L}}}
\newcommand {\namedlangset}[1] {\ensuremath{\textnormal{\textsc{#1}}}}
\newcommand {\family}[1]       {\ensuremath{\mathsf{#1}}}

\newcommand {\term}[1]      {\textit{#1}}
\newcommand {\namethm}[1]   {\term{#1} Theorem}
\newcommand {\usingthm}[1]  {(Using \namethm{#1})}

\newcommand {\reduce}[2]    {\ensuremath{\preceq_{#1}^{#2}}}
\newcommand {\complete}[2]  {\ensuremath{\reduce{#1}{#2}     %% ugly hack ahead!
                                         \hspace*{-4pt}\textnormal{-complete}}}

\newcommand {\indpar}[1]   {
  \par\leftskip=#1em
  \noindent\ignorespaces
}
\newenvironment{turing}[2] {
  \smallskip
  \indpar{2}
  \textit{Machine:} #1\\
  \textit{Input:} $#2$\\[5pt]
  \texttt{begin}
  \parskip=0pt
  \indpar{3}
}{
  \indpar{2}
  \texttt{end}
  \par\medskip
}

\newcommand {\ie}      {\textnormal{i.e. }}
\newcommand {\todo}[1] {{\large \textbf{TODO: #1}}}

%%% Defaults for languages and machines
\newcommand {\langL}          {\langset{L}}
\newcommand {\machineM}       {\machine{M}}
%%%

%%% Complexity Classes
\newcommand {\PTime}  {\family{P}}
\newcommand {\PH}     {\family{PH}}
\newcommand {\IP}     {\family{IP}}
\newcommand {\NP}     {\family{NP}}
\newcommand {\RP}     {\family{RP}}
\newcommand {\BPP}    {\family{BPP}}
\newcommand {\PSPACE} {\family{PSPACE}}
\newcommand {\FPi}    {\family{\Pi}}
\newcommand {\FSigma} {\family{\Sigma}}
%%%

\begin{document}

\makeheader {Saswat Padhi} {March 18, 2016}
            {CS 281A -- Computability and Complexity}

\begin{enumerate}[labelsep=2.5em, label=\textbf{\arabic{enumi}}]
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  % Q1
  \item A language $\langL$ is \term{Turing-recognizable} if there is a Turing
        machine that halts if and only if the input is in \langL. Prove for an
        explicit language that it is not Turing-recognizable.
  %-----------------------------------------------------------------------------
  \begin{proof}[Intuition]
    We know that problem \namedlangset{Halt} is \term{undecidable}. So, at least
    one of \namedlangset{Halt}, or $\overline{\namedlangset{Halt}}$ is not
    Turing-recognizable.
    But \namedlangset{Halt} is. So, $\overline{\namedlangset{Halt}}$ must not be!
  \end{proof}
  \begin{proof}
    Consider the complement language of \namedlangset{Halt}:
    $$ \overline{\namedlangset{Halt}}
    = \{ \langle \alpha, x \rangle \mid
         \machineM_\alpha \text{ never halts on } x \} $$
    We would prove that $\overline{\namedlangset{Halt}}$ is not
    Turing-recognizable.

    We begin by demonstrating that \namedlangset{Halt} is indeed
    Turing-recognizable.
    \begin{claim}\namedlangset{Halt} is Turing-recognizable.\end{claim}
    \begin{proof}
      Consider a universal TM \machine{U}. \\
      By construction, \machine{U} halts on an input $\langle \alpha, x \rangle$
      if and only if $\machineM_\alpha$ halts on $x$; because \machine{U} just
      simulates $\machineM_\alpha$ with at most a logarithmic time overhead.

      Clearly, \machine{U} thus \term{recognizes} \namedlangset{Halt}.
    \end{proof}

    \begin{assumption}
      For the sake of contradiction; assume the existence of a TM \machine{V}
      which recognizes $\overline{\namedlangset{Halt}}$ i.e. \machine{V} halts if
      and only if $\machineM_\alpha$ never halts on $x$.
    \end{assumption}

    Now consider the following TM, which we can construct using \machine{U} and
    \machine{V}:
    \begin{turing}{\machine{H}}{\langle  \alpha, x \rangle}
      simulate next step of \machine{U} on $\langle  \alpha, x \rangle$,
      halt with $1$ if \machine{U} halted. \\
      simulate next step of \machine{V} on $\langle  \alpha, x \rangle$,
      halt with $0$ if \machine{V} halted. \\
      repeat the above again
    \end{turing}

    \begin{claim}
      The TM \machine{H} \term{decides} \namedlangset{Halt}.
    \end{claim}
    \begin{proof}
      It is easy to see that \machine{H} halts for all inputs. Consider any
      input $\langle \alpha, x \rangle$. Then one of the following must hold:
      \begin{itemize}
        \item $\machineM_\alpha$ halts on on $x$, then \machine{U} must
          eventually halt. \\
          Thus \machine{H} must halt with $1$.
        \item $\machineM_\alpha$ never halts on $x$, then (\machine{U} never
          halts and) \machine{V} must eventually halt. \\
          Thus \machine{H} must halt with $0$.
      \end{itemize}
      Therefore, \machine{H} must eventually halt, in any case.

      Further, \machine{H} halts with $1$ on input $\langle \alpha, x \rangle$
      if and only if \machine{U} halts on the same input i.e. $\machineM_\alpha$
      halts on $x$. In other words, \machine{H} decides \namedlangset{Halt}.
    \end{proof}

    Hence, we have shown that using \machine{V}; we can \term{decide}
    \namedlangset{Halt} -- which is \term{undecidable}! \\
    Then our assumption regarding the existence of such a TM \machine{V} which
    recognizes $\overline{\namedlangset{Halt}}$ must be false.

    Therefore, $\overline{\namedlangset{Halt}}$ is not
    \term{Turing-recognizable}.
  \end{proof}


  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  % Q2
\item Give a polynomial-time algorithm for determining whether a given
      \term{2-CNF} formula is satisfiable.
  %-----------------------------------------------------------------------------
  \begin{proof}[Intuition]
    In case of \term{2-CNF}, assigning truth value to one literal in a
    clause, \textit{forces} a truth value on the other literal.
  \end{proof}
  \begin{proof}[Solution]
    Consider a \term{2-CNF} formula $\Delta$ defined on variables
    $x_1, x_2, \ldots, x_n$. \\
    We can rewrite any clause $(l_i \vee l_j)$, where $l_i$ and $l_j$ are
    literals; as $(\neg l_i \Rightarrow \l_j)$.

    Now consider a graph with each literal $l_k$ being a vertex and each edge
    being an \textit{implication}. For each clause $(l_i \vee l_j)$, we add
    edges $\overline{l_i} \longrightarrow l_j$ and
    $\overline{l_j} \longrightarrow l_i$, where $\overline{l_k}$ indicates the
    complement literal of $l_k$. So, construction of this graph can be done in
    time $O(p)$, where $p$ is the number of clauses in $\Delta$; but it is
    bounded by $O(n^2)$.

    Let's also represent a directed path over this graph from $l_i$ to $l_j$, as
    $l_i \rightsquigarrow l_j$. Since our graph edges model implications,
    $l_i \rightsquigarrow l_j$ would indicate $l_i \Rightarrow l_j$, due to the
    transitivity of implications.

    Note that a path $\overline{l_i} \rightsquigarrow l_i$ would force the
    assignment $l_i = 1$. Then we would face a contradiction for assigning a
    variable $x_i$ if:
    $$
      (x_i \rightsquigarrow \neg x_i) \wedge (\neg x_i \rightsquigarrow x_i)
      \qquad \text{as this would require,}
      \quad (x_i = 1) \wedge (\neg x_i = 1)
    $$

    We know that checking $l_i \rightsquigarrow l_j$ on a graph with $O(n)$
    vertices, is in polynomial-time. For example, a simple breadth-first-search
    would run in time $O(|V|+|E|) = O(n^2)$.

    So our algorithm could simply check the following: \\
    For each variable $x_k$ in $x_1, x_2, \ldots, x_n$; run two queries on the
    graph - check if $x_k \rightsquigarrow \neg x_k$ and
    $\neg x_k \rightsquigarrow x_k$. If both queries are satisfied for any
    variable $x_k$, then $\Delta \not\in \namedlangset{2-SAT}$. The algorithm
    would run in time $O(2 n \cdot n^2) = O(n^3)$. \\
    The soundness of this algorithm is a direct observation: if the algorithm
    finds some variable $x_k$ such that $x_k \rightsquigarrow \neg x_k$ and
    $\neg x_k \rightsquigarrow x_k$; then there exists no assignment for $x_k$,
    and thus $\Delta \not\in \namedlangset{2-SAT}$.

    \begin{claim}[Completeness]
      If $\Delta \not\in \namedlangset{2-SAT}$, the algorithm would eventually
      find some $x_i$ such that $x_i \rightsquigarrow \neg x_i$ and
      $\neg x_i \rightsquigarrow x_i$.
    \end{claim}
    \begin{proof}
      If $\Delta \not\in \namedlangset{2-SAT}$, then there must be at least one
      variable $x_i$ which can neither be assigned $0$, nor $1$; without
      violating at least one of the clauses.

      For the sake of contradiction, now assume that our algorithm does not
      detect at least one of these paths: $x_i \rightsquigarrow \neg x_i$ or
      $\neg x_i \rightsquigarrow x_i$ for this variable $x_i$. We will show that
      then there exists an assignment for $x_i$, which satisfies $\Delta$.

      For each variable $x_k$, we do the following:
      \begin{enumerate}
        \item if $x_k \rightsquigarrow \neg x_k$ was detected, assign $x_k = 0$.
        \item if $\neg x_k \rightsquigarrow x_k$ was detected, assign $x_k = 1$.
        \item if neither was detected, assign $x_k$ to $0$ or $1$ arbitrarily
      \end{enumerate}
      By our assumption, for no variable both cases (1) and (2) would be
      applicable.

      Now, since each edge of the graph corresponds to a clause in $\Delta$,
      this assignment is guaranteed to satisfy every clause, thus making it a
      satisfying assignment for $\Delta$!

      This contradicts the fact that $\Delta \not\in \namedlangset{2-SAT}$. \\
      The only reason could be our mistake in the assumption that our algorithm
      does not detect an inconsistency for variable $x_i$ --- which must be
      false.
    \end{proof}

    So we can decide if $\Delta \in \namedlangset{2-SAT}$, in time
    $O(n^2 + n^3) = O(n^3)$; and thus $\namedlangset{2-SAT} \in \PTime$.
  \end{proof}


  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  % Q3
  \item Let \langL\ be any \NP-complete language. Prove that $\langL \in \BPP$,
        if and only if $\langL \in \RP$.
  %-----------------------------------------------------------------------------
  \begin{proof}
    Let \langL\ be an arbitrary \NP-complete language as stated. \\
    Since $\RP \subseteq \BPP$ and \namedlangset{SAT} is \complete{p}{} for \NP,
    it would be enough to prove that:
    $$
    \text{If } \namedlangset{SAT} \in \BPP
    \text{, then } \namedlangset{SAT} \in \RP
    $$
    Per assumption, there must exist a randomized polynomial-time TM \machine{B}
    which decides \namedlangset{SAT}, with error rate $\leq \frac{1}{3}$, with
    $O(|x|^c)$ random bits for any input $x$.

    We construct the following randomized, polynomial-time TM \machine{R}, which
    \textit{uses} \machine{B} and decides \namedlangset{SAT}:
    \begin{turing}
          {\machine{R}}
          {\langle x, r \rangle
            \hfill x \text{ has } n \text{ variables: } v_0, v_2 \ldots v_{n-1}
            \quad \text{and} \quad |r| = n|x|^{c+1}}
      for $i$ = $0$ to $n-1$:
        \indpar{4}
        construct $x_i$ as $x$ with variable $v_i$ replaced by $0$ \\
        construct $r_i$ as the substring of $r$ within
          $[i \cdot |x|^{c+1}, (i+1) \cdot |x|^{c+1}]$ \\
        simulate \machine{B} on input $\langle x_i, r_i \rangle$ \\
        if simulation halts with $1$, assign $v_i \mapsto 0$ else
          assign $v_i \mapsto 1$
      \indpar{3}
      if the assignment to $v_0, v_2, \ldots , v_{n-1}$ satisfies $x$,
        output $1$ else output $0$
    \end{turing}

    The soundness of \machine{R} is a direct observation: due to the final check
    \machine{R} would never accept an $x \not\in \namedlangset{SAT}$. Although,
    \machine{R} might mistakenly declare an $x \in \namedlangset{SAT}$ as
    \namedlangset{UNSAT}; due to the fact that the particular assignment of
    $v_0, v_2, \ldots , v_{n-1}$ might not satisfy $x$.

    Next determine the false negative rate for \machine{R}; which is required to
    be $\leq \frac{1}{3}$, for \machine{R} to establish that
    $\namedlangset{SAT} \in \RP$. Clearly \machine{R} be incorrect, if at least
    $1$ of the simulations of \machine{B} turns out to be incorrect. The
    probability of this happening is $\frac{n}{3}$, which is too high!

    But we know that the error rate can be arbitrarily improved by running the
    probabilistic machines multiple times, independently. The probability that
    the majority of $k$ independent runs of \machine{B} is wrong is
    $\frac{1}{3^k}$. \\
    Now if we use $k$ runs instead of one run per variable, we would have error
    rate of \machine{R} $\leq \frac{n}{3^k}$. This quantity can be made
    $\leq \frac{1}{3}$ as required to be in \RP; by choosing a suitable $k$,
    specifically $k \geq 1 + \log_3{n}$. The new construction of \machine{R}
    would look like:
    \begin{turing}
          {\machine{R}}
          {\langle x, r \rangle
            \hfill x \text{ has } n \text{ variables: } v_0, v_2 \ldots v_{n-1}
            \quad \text{and} \quad |r| = (n+1)\log_3{n}|x|^{c+1}}
      $k := \log_3{n}$ \\
      for $i$ = $0$ to $n-1$:
        \indpar{4}
        construct $x_i$ as $x$ with variable $v_i$ replaced by $0$ \\
        $c_0 := 0 \quad c_1 := 0$ \\
        for $j$ = $0$ to $k$:
          \indpar{5}
          construct $r_i$ as the substring of $r$ within
            $[(ik+j-1) \cdot |x|^{c+1}, (ik+j) \cdot |x|^{c+1}]$ \\
          simulate \machine{B} on input $\langle x_i, r_i \rangle$ \\
          if simulation halts with $1$, increment $c_0$ else increment $c_1$
        \indpar{4}
        if $c_0 > c_1$, $v_i \mapsto 0$ else assign $v_i \mapsto 1$
      \indpar{3}
      if the assignment to $v_0, v_2, \ldots , v_{n-1}$ satisfies $x$,
        output $1$ else output $0$
    \end{turing}

    Note that, \machine{R} still runs in polynomial-time. Specifically it is
    $O(n\log{n}T_\machine{B}(n))$; where $T_\machine{B}$ is the running time of
    \machine{B}; since computing $k$, constructing $x_i$ and $r_i$ and checking
    if the assignments satisfy $x$ --- can all be done in smaller polynomials of
    $n$. Now, since we know that \machine{B} is an algorithm in \BPP,
    $T_\machine{B}$ is polynomial-time; which establishes that \machine{R} runs
    in polynomial-time.

    As \machine{R} now has a false-negative rate $\leq \frac{n}{3^k} \leq
    \frac{n}{3n} = \frac{1}{3}$; it establishes that
    $\namedlangset{SAT} \in \RP$; starting with the assumption that
    $\namedlangset{SAT} \in \BPP$. \\
    And since $\namedlangset{SAT} \in \RP$, we would have the same for any
    \NP-complete problem.
  \end{proof}
  \begin{remark}
    The above proof implies : $\NP \subseteq \RP$. But in fact $\NP = \RP$! \\
    This is because $\RP \subseteq \NP$, as discussed in class -- a problem
    being in \RP, shows that it has at least \textit{exponentially} many
    certificates; which is a subset of problems with at least \textit{one}
    certificate (\NP).
  \end{remark}


  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  % Q4
  \item Prove that there is a real number $0 < p < 1$ with the following
        property: given access to a coin with bias $p$, a randomized Turing
        machine can decide an undecidable language in polynomial time. By
        \textit{access} to the coin is meant the ability to receive any desired
        number of random bits $X_1, X_2, X_3 ... \in \{0,1\}$, each being an
        independent random variable with expectation $p$.
  %-----------------------------------------------------------------------------


  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  % Q5
  \item Prove that the polynomial hierarchy collapses if \namedlangset{TQBF} has
        a polynomial-time \textit{randomized} algorithm.
  %-----------------------------------------------------------------------------
  \begin{proof}
    If \namedlangset{TQBF} has a polynomial-time randomized algorithm,
    $\namedlangset{TQBF} \in \BPP$.

    Due to \namethm{Sipser-G\'{a}cs-Lautemann}\cite{Lautemann1983}:
    $\BPP \subseteq \FSigma_2 \cap \FPi_2$.
    Then, $\namedlangset{TQBF} \in \FSigma_2$.

    But we know that \namedlangset{TQBF} is \complete{p}{} for \PSPACE. So, any
    problem $\langset{P} \in \PSPACE$ can be reduced to \namedlangset{TQBF} in
    polynomial-time. Since $\PH \subseteq \PSPACE$, the reduction also holds for
    any problem $\langset{P} \in \PH$.

    But since we have assumed that $\namedlangset{TQBF} \in \FSigma_2$, we have
    actually shown that: \\
    $$ \forall \langset{P} \in \PH: \langset{P} \in \FSigma_2 $$
    In other words, the polynomial hierarchy \PH\ collapses to the $2^\text{nd}$
    level.
  \end{proof}


  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  % Q6
  \item Two players take turns choosing vertices from a directed graph $G$, such
        that the $i^\text{th}$ vertex chosen $v_i$, is distinct from $v_0, v_1,
        v_2, ..., v_{i-1}$ and reachable from $v_{i-1}$ by an edge. When a
        player has no vertices to choose from, the game ends and that player
        loses. On input a directed graph $G$, give a polynomial-space algorithm
        for deciding whether the player who starts the game can force a win,
        regardless of his opponent's choices. \\
        \textit{Comment:} This problem makes it clear why \PSPACE\ is often
        regarded as the class of adversarial games with two players.
  %-----------------------------------------------------------------------------
  \begin{proof}[Intuition]
    For the first player to be able to force a win, at any point in the game --
    there should \textit{exist} a move for him/her; which allows him to force a
    win, \textit{for all} possible moves of the second player. That sounds like
    \namedlangset{TQBF}!
  \end{proof}
  \begin{proof}[Solution]
    Consider the following recursive algorithm, similar to one for
    \namedlangset{TQBF}:

    \begin{minipage}{\linewidth}
    \begin{function}[H]
      \caption{FirstPlayerWins()}
      \DontPrintSemicolon
      \SetKwFunction{Union}{Union}\SetKwFunction{RemoveVertices}{RemoveVertices}

      \KwIn   {A graph $G$ \tcc*[r]{$V_G$ and $E_G$ are vertex and edge sets}}
      \KwOut  {$0$ if the first player can force a win, $1$ otherwise}

      \Begin{
        \For{\textnormal{each vertex} $x_i \in V_G$ \tcc*[r]{P1 chooses $x_i$}}{
          $flag_{won} \longleftarrow 1$ \;
          \For{\textnormal{each vertex $x_j$ s.t. $(x_i, x_j) \in E_G$}
            \tcc*[r]{P2 chooses $x_j$}
          } {
            \If{$\FirstPlayerWins{\RemoveVertices{$G, \{x_i, x_j\}$}} = 0$}{
              $flag_{won} \longleftarrow 0$ \tcc*[r]{could not force win}
              break
            }
          }
          \tcc*[r]{if player won for all choices of $x_j$}
          \lIf{$flag_{won} = 1$}{\Return{$1$}}
          \tcc*[r]{otherwise try next $x_i$}
        }
        \Return{$0$}
      }
    \end{function}
    \end{minipage}

    The call to function \texttt{RemoveVertices}, simply removes all supplied
    vertices from the provided graph, along with all of their incoming and
    outgoing edges.

    Soundness and completeness of \texttt{FirstPlayerWins} are directly observed
    since the algorithm explores all possible moves for both players.

    We now show that \texttt{FirstPlayerWins} uses polynomial-space. \\
    Let the space usage of \texttt{FirstPlayerWins} as a function of the
    argument graph $G$ be $S(G)$. Since during each recursive call, we only
    store $\langle G, x_i, x_j \rangle$ on the stack;
    \begin{align*}
      S(G) &= S(G') + |G| + 2
           & G' = \text{\tt RemoveVertices}(G, \{x_i, x_j\}) \\
           &= S(G') + O(n^2) & n = |V_G |
    \end{align*}
    Since we remove $2$ vertices from $G$ to obtain $G'$, the maximum depth of
    recursion can be $\frac{n}{2}$. Now, unrolling the recursive relation
    gives us $S(G) = O(n^3)$.

    Therefore \texttt{FirstPlayerWins} runs in space, polynomial in size of
    the input graph $G$.
  \end{proof}


  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  % Q7
  \item Prove that increasing the completeness parameter in the definition of
        \IP\ from $\frac{2}{3}$ to $1$, does not change this complexity class.
        What class do we get if we keep the completeness unchanged but increase
        the soundness from $\frac{2}{3}$ to $1$?
  %-----------------------------------------------------------------------------


  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  % Q8
  \item Prove that with Hadamard coding, it is in general impossible to recover
        the original codeword, if the received transmission is corrupted in
        $25\%$ or more of the coordinates.
  %-----------------------------------------------------------------------------

\end{enumerate}

\bibliographystyle{abbrv}
\bibliography{final}

\end{document}
